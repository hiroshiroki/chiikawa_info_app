"""
ã¡ã„ã‹ã‚æƒ…å ±ã¾ã¨ã‚ã‚¢ãƒ—ãƒª
Twitterã€ã¡ã„ã‹ã‚ãƒãƒ¼ã‚±ãƒƒãƒˆã€ã¡ã„ã‹ã‚ã‚¤ãƒ³ãƒ•ã‚©ã‹ã‚‰æƒ…å ±ã‚’è¡¨ç¤º
"""
import streamlit as st
from supabase import create_client
import json
from datetime import datetime, timedelta

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã¡ã„ã‹ã‚æƒ…å ±ã¾ã¨ã‚",
    page_icon="ğŸ­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #FF69B4;
        text-align: center;
        padding: 1rem 0;
    }
    .status-badge {
        display: inline-block;
        padding: 0.2rem 0.6rem;
        border-radius: 10px;
        font-size: 0.8rem;
        font-weight: bold;
        margin-left: 0.5rem;
        border: 1px solid;
    }
    .status-new {
        border-color: #4CAF50;
        color: #4CAF50;
    }
    .status-restock {
        border-color: #FF9800;
        color: #FF9800;
    }
    .uniform-item-container {
        min-height: 300px; /* Adjust as needed */
        overflow-y: auto;
    }
</style>
""", unsafe_allow_html=True)

# Supabaseæ¥ç¶š
@st.cache_resource
def init_supabase():
    return create_client(
        st.secrets["supabase_url"],
        st.secrets["supabase_key"]
    )

try:
    supabase = init_supabase()
except Exception as e:
    st.error("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼")
    st.info("Streamlit Secretsã« `supabase_url` ã¨ `supabase_key` ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    st.error(f"âš ï¸ è©³ç´°ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ========================================
# ã‚¿ã‚¤ãƒˆãƒ«
# ========================================

st.markdown('<h1 class="main-title">ğŸ­ ã¡ã„ã‹ã‚æƒ…å ±ã¾ã¨ã‚</h1>', unsafe_allow_html=True)
st.caption("å…¬å¼Twitterã€ã¡ã„ã‹ã‚ãƒãƒ¼ã‚±ãƒƒãƒˆã€ã¡ã„ã‹ã‚ã‚¤ãƒ³ãƒ•ã‚©ã‹ã‚‰è‡ªå‹•åé›†")

# ========================================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
# ========================================

with st.sidebar:
    st.header("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
    
    # ã‚«ãƒ†ã‚´ãƒª
    category = st.selectbox(
        "ã‚«ãƒ†ã‚´ãƒª",
        ["ã™ã¹ã¦", "ã‚°ãƒƒã‚º", "ãã˜", "ã‚¤ãƒ™ãƒ³ãƒˆ", "é£Ÿç©", "ãƒ—ãƒ©ã‚¤ã‚º", "ã‚¢ãƒ‹ãƒ¡", "ãã®ä»–"],
        help="ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã¿"
    )
    
    # æƒ…å ±æº
    source_options = {
        "twitter": "ğŸ¦ Twitter",
        "chiikawa_market": "ğŸ ã¡ã„ã‹ã‚ãƒãƒ¼ã‚±ãƒƒãƒˆ",
        "chiikawa_info": "ğŸ“° ã¡ã„ã‹ã‚ã‚¤ãƒ³ãƒ•ã‚©"
    }
    
    selected_sources = st.multiselect(
        "æƒ…å ±æº",
        list(source_options.keys()),
        default=list(source_options.keys()),
        format_func=lambda x: source_options[x],
        help="è¡¨ç¤ºã™ã‚‹æƒ…å ±æºã‚’é¸æŠ"
    )

    market_status = "ã™ã¹ã¦"
    if "chiikawa_market" in selected_sources:
        market_status = st.selectbox(
            "ã¡ã„ã‹ã‚ãƒãƒ¼ã‚±ãƒƒãƒˆå•†å“åŒºåˆ†",
            ["ã™ã¹ã¦", "æ–°å•†å“", "å†å…¥è·"],
            help="ã¡ã„ã‹ã‚ãƒãƒ¼ã‚±ãƒƒãƒˆã®å•†å“åŒºåˆ†ã§çµã‚Šè¾¼ã¿"
        )
    
    # æœŸé–“
    period = st.selectbox(
        "æœŸé–“",
        ["ã™ã¹ã¦", "24æ™‚é–“ä»¥å†…", "3æ—¥ä»¥å†…", "1é€±é–“ä»¥å†…", "1ãƒ¶æœˆä»¥å†…"],
        help="æŠ•ç¨¿æ—¥ã§çµã‚Šè¾¼ã¿"
    )
    
    # æ¤œç´¢
    search_text = st.text_input(
        "ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢",
        placeholder="ä¾‹: ã¬ã„ãã‚‹ã¿ã€ã‚¤ãƒ™ãƒ³ãƒˆ",
        help="ã‚¿ã‚¤ãƒˆãƒ«ã‚„æœ¬æ–‡ã‚’æ¤œç´¢"
    )
    
    # ç”»åƒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    only_with_images = st.checkbox(
        "ğŸ“¸ ç”»åƒã‚ã‚Šã®ã¿è¡¨ç¤º",
        value=False,
        help="ç”»åƒãŒå«ã¾ã‚Œã‚‹æŠ•ç¨¿ã®ã¿è¡¨ç¤º"
    )
    
    st.divider()
    
    # ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒœã‚¿ãƒ³
    if st.button("ğŸ”„ æ›´æ–°", use_container_width=True):
        st.cache_data.clear()
        st.rerun()

# ========================================
# ãƒ‡ãƒ¼ã‚¿å–å¾—
# ========================================

@st.cache_data(ttl=300)
def get_information(category, sources, period, search, only_images, market_status):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’å–å¾—"""
    query = supabase.table("information").select("*")
    
    if category != "ã™ã¹ã¦":
        query = query.eq("category", category)
    
    if sources:
        query = query.in_("source", sources)
    
    if period != "ã™ã¹ã¦":
        days_map = {"24æ™‚é–“ä»¥å†…": 1, "3æ—¥ä»¥å†…": 3, "1é€±é–“ä»¥å†…": 7, "1ãƒ¶æœˆä»¥å†…": 30}
        date_from = (datetime.now() - timedelta(days=days_map[period])).isoformat()
        query = query.gte("published_at", date_from)
    
    if search:
        query = query.or_(f"title.ilike.%{search}%,content.ilike.%{search}%")

    if only_images:
        # ç”»åƒãŒç©ºã§ãªã„ã€ã‹ã¤NULLã§ãªã„ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        query = query.not_.is_("images", "null")
        query = query.not_.eq("images", '[]')

    if "chiikawa_market" in sources and market_status != "ã™ã¹ã¦":
        status_value = "new" if market_status == "æ–°å•†å“" else "restock"
        query = query.eq("status", status_value)
        
    data = query.order("published_at", desc=True).limit(200).execute()
    return data.data

# ãƒ‡ãƒ¼ã‚¿å–å¾—å®Ÿè¡Œ
try:
    info_list = get_information(
        category,
        selected_sources,
        period,
        search_text,
        only_with_images,
        market_status
    )
except Exception as e:
    st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    info_list = []

# ========================================
# çµ±è¨ˆè¡¨ç¤º
# ========================================

st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
col1, col2, col3, col4 = st.columns(4)
col1.metric("ç·ä»¶æ•°", len(info_list))
col2.metric("ğŸ¦ Twitter", len([i for i in info_list if i['source'] == 'twitter']))
col3.metric("ğŸ ãƒãƒ¼ã‚±ãƒƒãƒˆ", len([i for i in info_list if i['source'] == 'chiikawa_market']))
col4.metric("ğŸ“° ã‚¤ãƒ³ãƒ•ã‚©", len([i for i in info_list if i['source'] == 'chiikawa_info']))
st.divider()

# ========================================
# æƒ…å ±ä¸€è¦§è¡¨ç¤º
# ========================================

if not info_list:
    st.info("ğŸ“­ è©²å½“ã™ã‚‹æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
else:
    st.subheader(f"ğŸ“° æœ€æ–°æƒ…å ± ({len(info_list)}ä»¶)")
    
    # 3åˆ—ã§è¡¨ç¤º
    cols = st.columns(3)
    
    for idx, item in enumerate(info_list):
        with cols[idx % 3]:
            with st.container(border=True, height=300):
                # ç”»åƒè¡¨ç¤º
                if item.get('images'):
                    try:
                        images = item['images'] if isinstance(item['images'], list) else json.loads(item['images'])
                        if images:
                            st.image(images[0], width=150) # æœ€åˆã®ç”»åƒã®ã¿ã‚’å›ºå®šå¹…ã§è¡¨ç¤º
                    except:
                        pass
                
                # ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒƒã‚¸
                title_html = f"**{item['title']}**"
                if item['source'] == 'chiikawa_market' and item.get('status'):
                    status_text = "æ–°å•†å“" if item['status'] == 'new' else "å†å…¥è·"
                    status_class = "status-new" if item['status'] == 'new' else "status-restock"
                    title_html += f'<span class="status-badge {status_class}">{status_text}</span>'
                st.markdown(title_html, unsafe_allow_html=True)
                
                # ãƒ¡ã‚¿æƒ…å ±
                # pub_date = item['published_at']
                # date_str = pub_date.split('T')[0] if isinstance(pub_date, str) else str(pub_date).split(' ')[0]
                # st.caption(f"ğŸ“… {date_str}")
                
                category_emoji = {"ã‚°ãƒƒã‚º": "ğŸ", "ãã˜": "ğŸ²", "ã‚¤ãƒ™ãƒ³ãƒˆ": "ğŸª", "é£Ÿç©": "ğŸ¬", "ãƒ—ãƒ©ã‚¤ã‚º": "ğŸ†", "ã‚¢ãƒ‹ãƒ¡": "ğŸ“º", "ãã®ä»–": "ğŸ“Œ"}
                emoji = category_emoji.get(item['category'], "ğŸ“Œ")
                st.caption(f"{emoji} {item['category']}")
                
                source_names = {"twitter": "ğŸ¦ Twitter", "chiikawa_market": "ğŸ ã¡ã„ã‹ã‚ãƒãƒ¼ã‚±ãƒƒãƒˆ", "chiikawa_info": "ğŸ“° ã¡ã„ã‹ã‚ã‚¤ãƒ³ãƒ•ã‚©"}
                st.caption(f"ğŸ“ {source_names.get(item['source'], item['source'])}")

                # ä¾¡æ ¼è¡¨ç¤º
                if item.get('price'):
                    st.caption(f"ğŸ’° {item['price']:,}å††")
                
                st.link_button("ğŸ”— è©³ç´°ã‚’è¦‹ã‚‹", item['url'], use_container_width=True)


st.divider()
st.caption("ğŸ’¡ æƒ…å ±ã¯è‡ªå‹•åé›†ã•ã‚Œã¾ã™ã€‚æœ€æ–°æƒ…å ±ã¯å„å…¬å¼ã‚µã‚¤ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
st.caption("Â©nagano / chiikawa committee")